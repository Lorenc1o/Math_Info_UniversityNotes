#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 11
\spacing single
\use_hyperref false
\papersize a4paper
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date true
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 2cm
\topmargin 3cm
\rightmargin 2cm
\bottommargin 3cm
\headheight 3cm
\headsep 3cm
\footskip 2cm
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
ANM - Tarea 2
\end_layout

\begin_layout Author
Jose Antonio Lorencio Abril
\end_layout

\begin_layout Date
19-3-2020
\end_layout

\begin_layout Subsubsection*
Hacer dos pasos del método del gradiente conjugado empezando en el vector
 
\begin_inset Formula $\left(\begin{array}{c}
0\\
0\\
0
\end{array}\right)$
\end_inset

 con el sistema 
\series bold

\begin_inset Formula 
\[
\boldsymbol{\left\{ \begin{array}{cccc}
10x_{1} & -x_{2} &  & =9\\
-x_{1} & 10x_{2} & -2x_{3} & =7\\
 & -2x_{2} & 10x_{3} & =6
\end{array}\right.}
\]

\end_inset

 y comparar los resultados con los de la tarea 1.
\begin_inset Formula 
\[
x_{0}=\left(\begin{array}{c}
0\\
0\\
0
\end{array}\right)\rightarrow r_{0}=\left(\begin{array}{c}
9\\
7\\
6
\end{array}\right)\rightarrow v_{0}=\left(\begin{array}{c}
9\\
7\\
6
\end{array}\right)
\]

\end_inset


\begin_inset Formula 
\[
y_{1}=\left(\begin{array}{c}
83\\
49\\
46
\end{array}\right)\rightarrow t_{1}=0.1215
\]

\end_inset


\begin_inset Formula 
\[
x_{1}=\left(\begin{array}{c}
\frac{10935}{10000}\\
\\
\frac{8505}{10000}\\
\\
\frac{729}{1000}
\end{array}\right)\rightarrow r_{1}=\left(\begin{array}{c}
\frac{-10845}{10000}\\
\\
\frac{10465}{10000}\\
\\
\frac{411}{1000}
\end{array}\right)
\]

\end_inset


\begin_inset Formula 
\[
s_{1}=0.0147\rightarrow v_{1}=\left(\begin{array}{c}
\frac{-9522}{10000}\\
\\
\frac{11494}{10000}\\
\\
\frac{4992}{10000}
\end{array}\right)
\]

\end_inset


\begin_inset Formula 
\[
y_{2}=\left(\begin{array}{c}
\frac{-53357}{5000}\\
\\
\frac{57239}{5000}\\
\\
\frac{6733}{2500}
\end{array}\right)\rightarrow t_{2}=0.0989
\]

\end_inset


\begin_inset Formula 
\[
x_{2}=\left(\begin{array}{c}
\frac{9993}{10000}\\
\\
\frac{9642}{10000}\\
\\
\frac{7784}{10000}
\end{array}\right)\rightarrow r_{2}=\left(\begin{array}{c}
\frac{1032}{10000}\\
\\
\frac{516}{10000}\\
\\
\frac{2328}{10000}
\end{array}\right)
\]

\end_inset


\end_layout

\begin_layout Standard
Para comparar los resultados voy a calcular la norma del residual tras la
 segunda iteración, 
\begin_inset Formula $r_{2}$
\end_inset

, en los tres métodos de la primera tarea y en este.
 Nótese que, en la tarea 1 puse como 
\begin_inset Formula $r_{2}$
\end_inset

 el que resultaba en el desarrollo del algortimo, aquí voy a recalcular
 como 
\begin_inset Formula $b-Ax_{2}$
\end_inset

 para Gauss-Seidel y para relajación, pues estos algoritmos van calculando
 
\begin_inset Formula $r_{i}$
\end_inset

 aparte, y no se corresponde con el residual exactamente.
 También lo haré para este mismo método.
 Queda, entonces:
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
\parallel r_{J}\parallel=0.58566;\qquad\parallel r_{GS}\parallel=0.17179;\qquad\parallel r_{R}\parallel=0.145797;\qquad\parallel r_{GC}\parallel=0.17035
\]

\end_inset


\end_layout

\begin_layout Standard
Por tanto, vemos como el residual en el método del gradiente conjugado es
 muy parecido a los de GaussSeidel y relajación, y estos tres parecen mejores
 que el de Jacobi.
 Sin embargo, 2 iteraciones son pocas y habría que estudiar cómo evolucionan
 estos residuales al avanzar en el algoritmo.
\end_layout

\end_body
\end_document
